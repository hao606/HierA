{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d957da",
   "metadata": {},
   "source": [
    "# HierA方法 方案设计"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9086267",
   "metadata": {},
   "source": [
    "### 一、符号定义\n",
    "$$\\begin{array}{c|c}\n",
    "\\hline\n",
    "{符号}&{描述}\\\\\n",
    "\\hline\n",
    "{U=\\{u_1,u_2,...,u_n\\}}&{用户集，u_i表示第i个用户}\\\\\n",
    "\\hline\n",
    "V = \\{v_1,v_2,...,v_n\\}& 用户数据集，v_i表示用户u_i的数据\\\\\n",
    "\\hline\n",
    "D = \\{D_1,D_2,...,D_n\\}& 数据值域按隐私等级划分的子区间\\\\\n",
    "\\hline\n",
    "\\varepsilon =\\{\\epsilon_1,\\epsilon_2,...,\\epsilon_n\\}&数据的隐私预算集合\\\\\n",
    "\\hline\n",
    "t_i & 数据v_i的隐私等级\\\\\n",
    "\\hline\n",
    "m & 用户数据的真实均值\\\\\n",
    "\\hline\n",
    "m^* & 用户数据的估计均值\\\\\n",
    "\\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c8737",
   "metadata": {},
   "source": [
    "### 二、数值型数据的分级收集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb29861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3a3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Harmony import Harmony\n",
    "from PiecewiseMechanism import PiecewiseMechanism as PM\n",
    "from multi_laplace import MultiLaplace  as Multi_Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18018479",
   "metadata": {},
   "source": [
    "###### 算法1. 本地分级扰动方法（LHP算法）：\n",
    "__输入：__ 用户数据$v$，数据值域的子区间划分$D=\\{D_1,D_2,...,D_k\\}$，各子区间相对应的隐私预算集合$ \\varepsilon = \\{\\epsilon_1,\\epsilon_2,...\\epsilon_k\\}$。\n",
    "\n",
    "__输出：__ 扰动后的用户数据$<t^*,v^*>$。\n",
    "- __步骤1__ 根据$v$所处区间，查询到其应采取的隐私等级$t，t\\in \\{1,2,...,k\\}$；\n",
    "- __步骤2__ 使用GRR方法对$t$进行扰动，得到扰动后的$t^*=GRR(t, \\epsilon_t)$；\n",
    "- __步骤3__ 使用用harmony方法对$v$进行离散扰动，得到扰动后的$v^*=Harmony(v, \\epsilon_t^*)$；\n",
    "- __步骤4__ 返回扰动后的$<t^*,v^*>$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f906f5e",
   "metadata": {},
   "source": [
    "算法1主要完成用户在本地对数据的隐私化处理。其中我们假设数据值域子区间的隐私等级从低到高排列，相对应的各隐私预算依次降低即$\\epsilon_1>\\epsilon_2>...>\\epsilon_k$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c528ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class user:\n",
    "    def __init__(self, range_division: tuple, epsilons: tuple):\n",
    "        self.range_division = range_division\n",
    "        self.epsilons = epsilons\n",
    "        self.levels = tuple(i for i in range(1, len(epsilons)+1))\n",
    "        \n",
    "    def get_level(self, value: float):\n",
    "        '''根据数据所在子区间，得到相应的隐私等级'''\n",
    "        v = value\n",
    "        if not -1 <= v <= 1:\n",
    "            raise Exception('输入值：{}，不在[-1,1]内'.format(v))\n",
    "        for i in range(len(self.range_division)):\n",
    "            if v < self.range_division[i]:\n",
    "                return i\n",
    "        return self.levels[-1]\n",
    "    def per_level(self, level, epsilon: float):\n",
    "        '''对隐私等级进行扰动'''\n",
    "        levels = list(self.levels)\n",
    "        p = np.e**epsilon / (np.e**epsilon + len(levels)-1)\n",
    "        if random.random() < p:\n",
    "            return level\n",
    "        else:\n",
    "            levels.remove(level)\n",
    "            return random.choice(levels)\n",
    "    \n",
    "    def per_value(self, value: float, epsilon: float):\n",
    "        '''对用户数据进行扰动'''\n",
    "        v = value\n",
    "        if not -1 <= v <= 1:\n",
    "            raise Exception('输入值：{}，超限'.format(v))\n",
    "        \n",
    "        rnd_1 = random.random()\n",
    "        v_ = -1 if rnd_1 < (1-v)/2 else 1\n",
    "        \n",
    "        p = np.e ** epsilon / (np.e ** epsilon + 1)\n",
    "        rnd_2 = random.random()\n",
    "        v_ = v_ if rnd_2 < p else -v_\n",
    "        return v_\n",
    "    \n",
    "    def lhp(self, value):\n",
    "        '''用户数据的本地扰动'''\n",
    "        level = self.get_level(value)\n",
    "        p_level = self.per_level(level, self.epsilons[level-1])\n",
    "        p_value = self.per_value(value, self.epsilons[p_level-1])\n",
    "        return (p_level, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c921e32",
   "metadata": {},
   "source": [
    "##### 算法2 收集端的隐私等级转换方法（PLC算法）：\n",
    "__输入：__ 隐私等级为i的数据集$V_i$，目标隐私等级$j$以及与隐私等级相对应的隐私预算$\\epsilon_i,\\epsilon_j$。\n",
    "\n",
    "__输出：__ 转换后的隐私等级为$j$的数据集集合$V_{ij}$。\n",
    "- __步骤1__ 对$V_i$中的每个数据$v$进行一下扰动：\n",
    "- __步骤2__ 计算$p_i = \\frac{e^{\\epsilon_i}}{e^{\\epsilon_i}+1},p_j=\\frac{e{\\epsilon_j}}{e^{\\epsilon_j}+1}$\n",
    "- __步骤3__ 对$V_i$中的每个数据$v$进行以下操作：\n",
    "- __步骤4__ 从[0,1]中均匀随机的抽取$x$，\n",
    "- __步骤5__ 如果 $x < \\frac{p_i+p_j-1}{2p_i-1}$，则 $v^* = v$\n",
    "- __步骤6__ 否则$v^* = -v$\n",
    "- __步骤7__ 返回等级转换后的数据集$V_{ij}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b7340",
   "metadata": {},
   "source": [
    "算法2主要实现用户数据的可重复使用，增加可用的数据量从而提高数据分析时的准确性。具体地，通过二次扰动将低等级的数据转换成高等级的数据，从而大幅增加每一隐私等级内的数据量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c09788e",
   "metadata": {},
   "source": [
    "##### 算法3 数值型数据的分级收集方法（HierA算法）\n",
    "__输入：__ 用户数据集$V=\\{v_1,v_2,...,v_n\\}$，数据值域的子区间划分$D=\\{D_1,D_2,...,D_n\\}$，与区间划分相对应的隐私预算集合$\\varepsilon = \\{ \\epsilon_1,\\epsilon_2,...,\\epsilon_n\\}$, 数据量扩展倍数$\\mu$。\n",
    "\n",
    "__输出：__ 估计均值$m^*$。\n",
    "\n",
    "__用户端__：\n",
    "- __步骤1__ 用户$u_i$在本地采用LHP算法对自己的数据$v_i$进行扰动，得到扰动后的元组$<t_i^*,v_i^*> = LHP(D,\\varepsilon,v_i)$。之后将元组$<t_i^*, v_i^*>$发送给数据收集方。\n",
    "\n",
    "__收集端__:\n",
    "- __步骤2__ 将接收到的用户数据按照隐私等级进行分类得到$\\{V_1,V_2,...,V_k\\}$；\n",
    "- __步骤3__ 根据数据重复使用次数$\\mu$，对分类后的数据集使用PLC算法进行转换，得到转换后的数据集$\\{V_i,V_{i(i+1)},V_{i(i+2)},...,V_{i(i+\\mu-1)}\\}$，其中$V_{ij} = PLC(V_i,\\epsilon_i,\\epsilon_j)$。\n",
    "- __步骤4__ 得到如下数据集矩阵，每一列代表一个隐私等级：\n",
    "$$\\begin{bmatrix}\n",
    "V_1&V_{12}&\\cdots&V_{1(1+\\mu-1)}& & \\\\\n",
    " &V_2&V_{2(3)}&\\cdots&V_{2(2+\\mu-1)}&\\\\\n",
    " & &\\ddots&\\ddots&\\ddots&\\ddots \\\\\n",
    "\\end{bmatrix}$$\n",
    "- __步骤5__ 将同一隐私等级的数据集进行合并，同时加入补偿数据集\n",
    "    - for $i$ in $\\{1,2,3,...,k\\}$:\n",
    "         - if $i+\\mu-1 < k$:\n",
    "            - $V_i^* = (\\mu-k+i)V_i$\n",
    "         - $V_i^* = V_i^* + V_{(i-1)i} + ... + V_{1i}$\n",
    "\n",
    "    - 得到扩大后的数据集$V^* = \\{V_1^*, V_2^*,...,V_k^*\\}$\n",
    "- __步骤6__ 对$V^*$中的每个数据集$V_i^*$进行以下操作：\n",
    "    - 统计$V_i^*$中的1和-1数量，分别记做$n_1$和$n_2$；\n",
    "    - $N = n_1 + n_2, p_i = \\frac{e^{\\epsilon_i}}{e^{\\epsilon_i}+1}$\n",
    "    - $n_1^* = \\frac{p_i\\cdot N - n_2}{2\\cdot p_i-1}$\n",
    "    - $n_2^* = \\frac{p_i\\cdot N - n_1}{2\\cdot p_i-1}$\n",
    "    - 对$n_1^*$和$n_2^*$进行校正，若大于N则令其等于N，若小于0则令其等于0。\n",
    "    - $S(V_i^*) = n_1^* - n_2^*$\n",
    "- __步骤7__ 计算均值$m^*$：$m^* = \\frac{1}{|V^*|}\\sum_{i=1}^kS(V_i^*)$\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cbc907",
   "metadata": {},
   "source": [
    "算法3通过结合算法1和算法2，描述了在本地差分隐私下对数值型数据进行分级收集分析的全过程。详细描述了收集方从用户端收集完数据之后进行均值估计的过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208b9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class aggregator:\n",
    "    def __init__(self, range_division: tuple, epsilons: tuple, mu: int):\n",
    "        self.range_division = range_division\n",
    "        self.epsilons = epsilons\n",
    "        self.mu = mu\n",
    "        self.levels = tuple(i for i in range(1, len(epsilons)+1))\n",
    "        \n",
    "    def classify(self, userdata: list) -> dict:\n",
    "        '''对收集到的用户数据，按照隐私等级进行分类'''\n",
    "        dataset = {k: [] for k in self.levels}\n",
    "        for level, data in userdata:\n",
    "            dataset[level].append(data)\n",
    "        return dataset\n",
    "    \n",
    "    @staticmethod\n",
    "    def plc(dataset: list, epsilon_i: float, epsilon_j: float) -> list:\n",
    "        '''隐私等级转换机制'''\n",
    "        if epsilon_i < epsilon_j:\n",
    "            raise Exception('目标隐私等级{}输入错误'.format(epsilon_j))\n",
    "        p_i = np.e ** epsilon_i / (np.e**epsilon_i+1)\n",
    "        p_j = np.e ** epsilon_j / (np.e**epsilon_j+1)\n",
    "        result = []\n",
    "        for value in dataset:\n",
    "            rnd = random.random()\n",
    "            if rnd < (p_i+p_j-1) / (2*p_i-1):\n",
    "                _v = value\n",
    "            else:\n",
    "                _v = -value\n",
    "            result.append(_v)\n",
    "        return result\n",
    "    \n",
    "    def data_expand(self, classified_data: dict)-> dict:\n",
    "        '''对用户数据进行隐私等级转换以扩大数据量'''\n",
    "        levels = self.levels\n",
    "        epsilons = self.epsilons\n",
    "        mu = self.mu\n",
    "\n",
    "        result_data = { k : [v.copy()] for k, v in classified_data.items() }\n",
    "        \n",
    "        # 将低等级数据转换成高等级数据实现数据的重复使用\n",
    "        for level, dataset in classified_data.items():\n",
    "            for t_level in range(level+1, min(level+ mu,levels[-1]+1)): \n",
    "                result_data[level].append(self.plc(dataset, epsilons[level-1], epsilons[t_level-1]))\n",
    "        # 合并相同隐私等级的数据\n",
    "        last_result_data = {k : v.copy() for k, v in classified_data.items()}\n",
    "        \n",
    "        for j in last_result_data.keys():\n",
    "            if j+mu-1 > self.levels[-1]:\n",
    "                last_result_data[j] *= (mu - levels[-1] + j) \n",
    "                \n",
    "            for i in range(j-1, max(0, j-mu), -1):\n",
    "                last_result_data[j] += result_data[i][j-i]\n",
    "        return last_result_data\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sum(dataset: list, epsilon: float):\n",
    "        '''求和'''\n",
    "        \n",
    "        n_1 = dataset.count(1)\n",
    "        n_2 = dataset.count(-1)\n",
    "        n = n_1 + n_2\n",
    "        p = np.e**epsilon / (np.e**epsilon+1)\n",
    "        n_1_ = (n*p-n_2) / (2*p-1)\n",
    "        n_2_ = (n*p-n_1) / (2*p-1)\n",
    "        if not 0 <= n_1_ <= n:\n",
    "            n_1_ = 0 if n_1_ < 0 else n\n",
    "        if not 0 <= n_2_ <= n:\n",
    "            n_2_ = 0 if n_2_ < 0 else n\n",
    "        s = n_1_ - n_2_\n",
    "        return s\n",
    "    \n",
    "    def average(self, userdata: list) -> float:\n",
    "        '''求均值'''\n",
    "        classified_data = self.classify(userdata)\n",
    "        if self.mu == 1:\n",
    "            expand_data = classified_data\n",
    "        else:\n",
    "            expand_data = self.data_expand(classified_data)\n",
    "        s = 0\n",
    "        n = 0\n",
    "        for level, dataset in expand_data.items():\n",
    "            n += len(dataset)\n",
    "            s += self._sum(dataset, self.epsilons[level-1])\n",
    "        m = s/n\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb17bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HierA(userdata: tuple, range_division: tuple, epsilons: tuple, mu = 2):\n",
    "    '''put things together'''\n",
    "    \n",
    "    #用户端：\n",
    "    lhp = user(range_division, epsilons).lhp\n",
    "    send_data = list()\n",
    "    for v in userdata:\n",
    "        send_data.append(lhp(v))\n",
    "\n",
    "    #收集端：\n",
    "    average = aggregator(range_division, epsilons, mu).average\n",
    "    m = average(send_data)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89cb0e8",
   "metadata": {},
   "source": [
    "### 三、小批量随机梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0265784",
   "metadata": {},
   "source": [
    "以线性回归模型为例研究分级收集方法在随机梯度下降法中的应用。\n",
    "\n",
    "假设每个用户拥有一组多元数据$<\\boldsymbol{x_i}, y_i>$，其中$\\boldsymbol{x_i} \\in [-1,1]^d,y_i \\in [-1,1]$。目标模型为线性模型$f(\\boldsymbol x_i) = \\boldsymbol \\alpha^T\\boldsymbol x_i + b$。\n",
    "令$\\boldsymbol\\beta = [b,\\alpha_1,\\alpha_2,...,\\alpha_d],\\boldsymbol x_i =[1,x_{i1},x_{i2},...,x_{id}]$，则模型训练最终目标为得到参数向量$\\boldsymbol\\beta^*$，满足条件$$\\boldsymbol\\beta^* = arg\\ \\underset {\\boldsymbol \\beta}min[\\frac{1}{n}\\sum_{i=1}^nL(\\boldsymbol\\beta;\\boldsymbol x_i,y_i)+\\frac{\\lambda}{2}\\Vert \\boldsymbol \\beta \\Vert^2_2]$$\n",
    "其中$L(\\cdot)$表示损失函数，$L(\\boldsymbol \\beta;\\boldsymbol x_i,y_i)=(\\boldsymbol x_i^T \\beta - y_i)^2$；$\\lambda$表示正则项系数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c43932",
   "metadata": {},
   "source": [
    "小批量的随机梯度下降法求$\\boldsymbol\\beta^*$。具体地，首先初始化一个参数向量$\\boldsymbol\\beta^*_0$，然后按下式进行迭代更新:\n",
    "$$\\boldsymbol\\beta_{t+1} = \\boldsymbol\\beta_t - \\gamma_t\\cdot \\frac{1}{|G|}\\sum_{i=1}^{|G|}\\nabla R(\\boldsymbol\\beta_t;\\boldsymbol x_i,y_i)$$\n",
    "\n",
    "其中：\n",
    "- $R(\\boldsymbol\\beta;\\boldsymbol x_i,y_i)=L(\\boldsymbol\\beta;\\boldsymbol x_i,y_i)+\\frac{\\lambda}{2}\\Vert \\boldsymbol \\beta \\Vert^2_2$；\n",
    "\n",
    "- $\\nabla R(\\boldsymbol\\beta;\\boldsymbol x_i,y_i)$是$R(\\boldsymbol\\beta;\\boldsymbol x_i,y_i)$在$\\boldsymbol\\beta_t$处的梯度；\n",
    "\n",
    "- $\\gamma_t$表示第$t$次迭代的学习效率，设$\\gamma_t=O(1/\\sqrt t) $\n",
    "- $|G|$是每次进行迭代时所使用的样本点数,即每组用户数。$|G|=\\Omega(\\frac{d(log(d))}{\\epsilon^2})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd4c46",
   "metadata": {},
   "source": [
    "在本地差分隐私环境下，收集方首先将初始化得到的参数向量$\\boldsymbol\\beta^*_0$发送给第一组用户，该组用户在本地根据收到的参数向量，计算得到梯度$\\nabla R$，然后使用数值型数据的扰动算法对$\\nabla R$进行扰动得到$\\nabla R^*$并发送给收集方。收集方根据收集到的数据，求取均值。本文使用算法3实现对$\\nabla R$的扰动和求均值。具体步骤见__算法4__。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b340de28",
   "metadata": {},
   "source": [
    "在对梯度向量的分级扰动收集中，用户并不根据梯度向量中的各个偏导数$\\frac{\\partial R}{\\partial \\alpha_j}(\\boldsymbol x_i,y_i)$的本身大小对其进行隐私分级，而是根据各偏导数对应的$\\boldsymbol x_i$分量$x_{ij}$的大小对该偏导数进行隐私分级。为实验方便，我们将每维数据的值域平均分为5个子区间$\\{[-1,-0.6),[-0.6,-0.2),[-0.2,0.2), [0.2,0.6),[0.6,1]\\}$,相对应的隐私预算集合为$\\{2\\epsilon, 1.75\\epsilon,1.5\\epsilon,1.25\\epsilon,\\epsilon\\}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43dfb04",
   "metadata": {},
   "source": [
    "在一般的随机梯度下降中每个样本数据往往需要参与多次循环迭代，直至参数向量变化足够小为止。然而，本地差分隐私环境下，如果每个样本点参与多次迭代，为保护用户隐私，用户每次所采用的隐私预算将会被严重分割，从而造成用户数据可用性急剧降低。因此，在本地差分隐私环境中，每个用户只参与一次循环迭代。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314176bc",
   "metadata": {},
   "source": [
    "###### 算法4 小批量随机梯度下降\n",
    "__输入：__ 用户集$U=\\{u_1,u_2,...,u_n\\}$，用户数据集$V=\\{(\\boldsymbol x_1,y_1),(\\boldsymbol x_2,y_2),...,(\\boldsymbol x_n, y_n)\\}$，值域子区间集合$D=\\{D_1,D_2,...,D_k\\}$，与区间划分相对应的隐私预算集合$\\varepsilon = \\{ \\epsilon_1,\\epsilon_2,...,\\epsilon_k\\}$, 数据量扩展倍数$\\mu$。梯度下降中每组人数$G=\\frac{2d logd} {\\epsilon^2}$，参数更新的学习效率$\\gamma=1/\\sqrt t$，正则项系数$\\lambda=10^{-4}$。\n",
    "\n",
    "__输出：__参数向量$\\boldsymbol\\beta^*$\n",
    "- __step 0__ 收集方与用户就数据的隐私等级划分$D,\\varepsilon$达成一致\n",
    "- __step 1__ 从[0,1]中随机抽取初始化参数向量$\\beta^*_0\\in [0,1]^{d+1}$\n",
    "- __step 2__ 收集方从用户集U中不放回地随机抽取G个用户，向他们发送$\\beta^*_0$\n",
    "- __step 3__ 接收到参数向量的每个用户在本地根据自己的数据对梯度向量的各偏导数进行计算,如果该值大于1则令其等于1，如果该值小于-1，则令其等于-1。使用算法1进行扰动后将进行隐私处理后的梯度向量发送给收集方。\n",
    "- __step 4__ 收集方根据接收到的梯度集，使用算法3对各个偏导数进行均值估计，之后对参数向量进行更新。\n",
    "- __step 5__ 重复step 2到step 4直到所有用户均进行了参与一次模型训练。\n",
    "- __step 6__ 得到最终的参数向量$\\boldsymbol \\beta^*$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622a534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_f(beta: list, x:tuple):\n",
    "    '''目标模型函数'''\n",
    "    return np.array(beta).dot(np.array(x))\n",
    "\n",
    "def loss_f(beta: list, x: list, y: float):\n",
    "    '''损失函数'''\n",
    "    return (predict_f(beta, x)-y)**2\n",
    "\n",
    "def penalty(beta: list, lam: float):\n",
    "    '''正则项'''\n",
    "    return lam*sum([b*b for b in beta[1:]])/2\n",
    "\n",
    "def target_f(beta: list,lam: float, x: tuple, y: float):\n",
    "    '''带惩罚项的残差函数'''\n",
    "    return loss_f(beta, x, y) + penalty(beta, lam)\n",
    "\n",
    "def gradient_f(beta: list, lam: float, x: tuple, y: float):\n",
    "    '''残差函数的梯度'''\n",
    "\n",
    "    loss_f_g = [2*x_i*(predict_f(beta,x)-y) for x_i in x]\n",
    "    penalty_g = [0] + [lam * abs(b) for b in beta[1:]]\n",
    "    return  [a + b for a,b in zip(loss_f_g, penalty_g)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faccf447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_random_order(data):\n",
    "    '''为数据生成随机索引，以实现随机选取，随机分组'''\n",
    "    indexes = [i for i, _ in enumerate(data)]\n",
    "    random.shuffle(indexes)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09078c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmony_mb_sgd(x: tuple, y: tuple,range_division:tuple,\\\n",
    "                   epsilon: float, lam=0.0001):\n",
    "    '''小批量随机梯度下降并用Harmony方法进行隐私保护'''\n",
    "    beta = [random.random() for _ in range(len(x[0])+1)] #随机初始化一个参数向量beta\n",
    "    d = len(x[0])+1\n",
    "    group_n = max(math.ceil(d*math.log(d)/epsilon**2), 1000)\n",
    "    \n",
    "    t = 0 # t表示迭代次数\n",
    "    gs = [] # 用于存放每次迭代收集到的用户数据梯度。\n",
    "    n = 0 # 用于统计已参与的用户数量\n",
    "    \n",
    "    harmony = Harmony(epsilon).encode\n",
    "    for i in in_random_order(y):\n",
    "        n += 1\n",
    "        \n",
    "        #计算得到在用户user_i的梯度\n",
    "\n",
    "        gradient_i = gradient_f(beta, lam, [1]+list(x[i]), y[i])\n",
    "        \n",
    "#         print(i,gradient_i)\n",
    "        #对梯度各分量进行裁剪，使其在[-1,1]之间\n",
    "        for k in range(len(gradient_i)):\n",
    "            if gradient_i[k] > 1:\n",
    "                gradient_i[k] = 1\n",
    "            elif gradient_i[k] < -1:\n",
    "                gradient_i[k] = -1\n",
    "         \n",
    "        #使用Harmony方法对梯度进行隐私处理\n",
    "        p_gradient_i = [0 for _ in gradient_i]# 存放扰动后的梯度\n",
    "        \n",
    "        sample = random.choice(range(len(gradient_i))) # 每次采样一个分量\n",
    "        p_gradient_i[sample] = (harmony(gradient_i[sample]))\n",
    "        gs.append(p_gradient_i)     \n",
    "        \n",
    "        if n % group_n == 0:\n",
    "            t += 1\n",
    "            g_mean =[] #用于存放每组数据梯度的均值\n",
    "            for i in range(len(gs[0])):\n",
    "                g_i = [] #用于存放一组梯度中所有的第i个分量\n",
    "                for g_j in gs:\n",
    "                    g_i.append(g_j[i])\n",
    "                g_mean.append(sum(g_i)/len(g_i))\n",
    "            # 进行参数向量更新：\n",
    "            gamma = 1/t**0.5\n",
    "            beta = [a-gamma*b for a, b in zip(beta,g_mean)]\n",
    "            gs = []\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5453fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hiera_mb_sgd(x: tuple, y: tuple, range_division: tuple,\\\n",
    "                 epsilon: float ,mu=2, lam=0.0001):\n",
    "    '''小批量随机梯度下降并用HierA方法进行隐私保护'''\n",
    "    beta = [random.random() for _ in range(len(x[0])+1)] #随机初始化一个参数向量beta\n",
    "    d = len(x[0])+1\n",
    "    group_n = max(math.ceil(d*math.log(d)/epsilon**2), 1000)\n",
    "    \n",
    "    t = 0 # t表示迭代次数\n",
    "    gs = [] # 用于存放每次迭代收集到的用户数据梯度。\n",
    "    n = 0 # 用于统计已参与的用户数量\n",
    "    \n",
    "    epsilons = tuple(i*epsilon for i in np.arange(5, 0, -1))\n",
    "    for i in in_random_order(y):\n",
    "        n += 1\n",
    "        \n",
    "        #计算得到在用户user_i的梯度\n",
    "        gradient_i = gradient_f(beta, lam, [1]+list(x[i]), y[i])\n",
    "        # print(gradient_i)\n",
    "        #对梯度各分量进行裁剪，使其在[-1,1]之间\n",
    "        for k in range(len(gradient_i)):\n",
    "            if gradient_i[k] > 1:\n",
    "                gradient_i[k] = 1\n",
    "            elif gradient_i[k] < -1:\n",
    "                gradient_i[k] = -1\n",
    "                \n",
    "        # 对梯度各分量进行分级扰动：\n",
    "        p_gradient_i = []# 存放扰动后的梯度\n",
    "        p_gradient_i = [(5,0) for _ in gradient_i]# 存放扰动后的梯度\n",
    "        \n",
    "        sample = random.choice(range(len(gradient_i))) # 每次采样一个分量 \n",
    "        \n",
    "        _x = [1] + list(x[i])\n",
    "        user_i = user(range_division, epsilons)\n",
    "        level = user_i.get_level(_x[sample])\n",
    "        p_level = user_i.per_level(level, epsilons[level-1])\n",
    "        p_value = user_i.per_value(gradient_i[sample], epsilons[p_level-1])\n",
    "        p_gradient_i[sample] = ((p_level,p_value))\n",
    "\n",
    "#         for x_ij, grad in zip([1]+list(x[i]),gradient_i):\n",
    "#                 level = user_i.get_level(x_ij)\n",
    "#                 p_level = user_i.per_level(level, epsilons[level-1])\n",
    "#                 p_value = user_i.per_value(grad, epsilons[p_level-1])\n",
    "#                 p_gradient_i.append((p_level,p_value))\n",
    "        gs.append(p_gradient_i)\n",
    "        \n",
    "        if n % group_n == 0:\n",
    "            t += 1\n",
    "            g_mean =[] #用于存放每组数据梯度的均值\n",
    "            server = aggregator(range_division, epsilons, mu)\n",
    "            for i in range(len(gs[0])):\n",
    "                g_i = [] #用于存放一组梯度中所有的第i个分量\n",
    "                for g_j in gs:\n",
    "                    g_i.append(g_j[i])\n",
    "                g_mean.append(server.average(g_i))\n",
    "            # 进行参数向量更新：\n",
    "            gamma = 1/t**0.5\n",
    "            beta = [a-gamma*b for a, b in zip(beta,g_mean)]\n",
    "            gs = []\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5b5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm_mb_sgd(x: tuple, y: tuple,range_division:tuple, \\\n",
    "              epsilon: float, lam=0.0001):\n",
    "    '''小批量随机梯度下降并用PM方法进行隐私保护'''\n",
    "    beta = [random.random() for _ in range(len(x[0])+1)] #随机初始化一个参数向量beta\n",
    "    d = len(x[0])+1\n",
    "    group_n = max(math.ceil(d*math.log(d)/epsilon**2), 1000)\n",
    "    \n",
    "    t = 0 # t表示迭代次数\n",
    "    gs = [] # 用于存放每次迭代收集到的用户数据梯度。\n",
    "    n = 0 # 用于统计已参与的用户数量\n",
    "    \n",
    "    pm = PM(epsilon).encode\n",
    "    for i in in_random_order(y):\n",
    "        n += 1\n",
    "        \n",
    "        #计算得到在用户user_i的梯度\n",
    "        gradient_i = gradient_f(beta, lam, [1]+list(x[i]),y[i])\n",
    "        \n",
    "        #对梯度各分量进行裁剪，使其在[-1,1]之间\n",
    "        for k in range(len(gradient_i)):\n",
    "            if gradient_i[k] > 1:\n",
    "                gradient_i[k] = 1\n",
    "            elif gradient_i[k] < -1:\n",
    "                gradient_i[k] = -1\n",
    "         \n",
    "        #使用PM方法对梯度进行隐私处理\n",
    "        p_gradient_i = [0 for _ in gradient_i]# 存放扰动后的梯度\n",
    "        \n",
    "        sample = random.choice(range(len(gradient_i))) # 每次采样一个分量\n",
    "        p_gradient_i[sample] = (pm(gradient_i[sample]))\n",
    "        gs.append(p_gradient_i)  \n",
    "        \n",
    "#         p_gradient_i = []# 存放扰动后的梯度\n",
    "#         for grad in gradient_i:\n",
    "#                 p_gradient_i.append(pm(grad))\n",
    "#         gs.append(p_gradient_i)\n",
    "        \n",
    "        if n % group_n == 0:\n",
    "            t += 1\n",
    "            g_mean =[] #用于存放每组数据梯度的均值\n",
    "            for i in range(len(gs[0])):\n",
    "                g_i = [] #用于存放一组梯度中所有的第i个分量\n",
    "                for g_j in gs:\n",
    "                    g_i.append(g_j[i])\n",
    "                g_mean.append(sum(g_i)/len(g_i))\n",
    "            # 进行参数向量更新：\n",
    "            gamma = 1/t**0.5\n",
    "            beta = [a-gamma*b for a, b in zip(beta,g_mean)]\n",
    "            gs = []\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1ac116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilaplace_mb_sgd(x: tuple, y: tuple, range_division: tuple, \\\n",
    "                        epsilon: float, lam=0.0001):\n",
    "    '''小批量随机梯度下降并用PM方法进行隐私保护'''\n",
    "    beta = [random.random() for _ in [1]+list(x[0])] #随机初始化一个参数向量beta\n",
    "    d = len(x[0])+1\n",
    "    group_n = max(math.ceil(d*math.log(d)/epsilon**2), 1000)\n",
    "    \n",
    "    t = 0 # t表示迭代次数\n",
    "    gs = [] # 用于存放每次迭代收集到的用户数据梯度。\n",
    "    n = 0 # 用于统计已参与的用户数量\n",
    "    \n",
    "    epsilons = tuple(i*epsilon for i in np.arange(5, 0, -1))\n",
    "    multi_laplace = Multi_Laplace(range_division, epsilons).encode\n",
    "    for i in in_random_order(y):\n",
    "        n += 1\n",
    "        \n",
    "        #计算得到在用户user_i的梯度\n",
    "        gradient_i = gradient_f(beta, lam, [1]+list(x[i]),y[i])\n",
    "        \n",
    "        #对梯度各分量进行裁剪，使其在[-1,1]之间\n",
    "        for k in range(len(gradient_i)):\n",
    "            if gradient_i[k] > 1:\n",
    "                gradient_i[k] = 1\n",
    "            elif gradient_i[k] < -1:\n",
    "                gradient_i[k] = -1\n",
    "         \n",
    "        #使用分级的laplace方法对梯度进行隐私处理\n",
    "        \n",
    "        p_gradient_i = [0 for _ in gradient_i]# 存放扰动后的梯度\n",
    "        \n",
    "        sample = random.choice(range(len(gradient_i))) # 每次采样一个分量\n",
    "        p_gradient_i[sample] = (multi_laplace(gradient_i[sample]))\n",
    "        gs.append(p_gradient_i)  \n",
    "        \n",
    "#        p_gradient_i = []# 存放扰动后的梯度\n",
    "#         for grad in gradient_i:\n",
    "#                 p_gradient_i.append(multi_laplace(grad))\n",
    "#         gs.append(p_gradient_i)        \n",
    "        \n",
    "        if n % group_n == 0:\n",
    "            t += 1\n",
    "            g_mean =[] #用于存放每组数据梯度的均值\n",
    "            for i in range(len(gs[0])):\n",
    "                g_i = [] #用于存放一组梯度中所有的第i个分量\n",
    "                for g_j in gs:\n",
    "                    g_i.append(g_j[i])\n",
    "                g_mean.append(sum(g_i)/len(g_i))\n",
    "            # 进行参数向量更新：\n",
    "            gamma = 1/t**0.5\n",
    "            beta = [a-gamma*b for a, b in zip(beta,g_mean)]\n",
    "            gs = []\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d06819",
   "metadata": {},
   "source": [
    "### 三、实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0d42e",
   "metadata": {},
   "source": [
    "### 1 实验数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673dcc4f",
   "metadata": {},
   "source": [
    "- 合成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af752da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a2acc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['font.sans-serif'] = [\"SimHei\"]\n",
    "mpl.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2afd5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(loc=0.5, scale=0.1, size=10**5):\n",
    "    '''正态分布'''\n",
    "    data = np.clip(np.random.normal(loc=loc, scale=scale, size=size), a_min=-1, a_max=1)\n",
    "    return tuple(data)\n",
    "\n",
    "def uniform(low=-1, high=1, size=10**5):\n",
    "    '''均匀分布'''\n",
    "    data = np.random.uniform(low=low, high=high, size=size)\n",
    "    return tuple(data)\n",
    "\n",
    "def exponent(scale=1,size =10**5):\n",
    "    '''指数分布'''\n",
    "    data = 2 * np.clip(np.random.exponential(scale=scale, size=size), a_min=0, a_max=1) - 1\n",
    "    return tuple(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7428cc54",
   "metadata": {},
   "source": [
    "- 真实数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9a526f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adult_age():\n",
    "    '''get dataset: adult_age'''\n",
    "    mydb = mysql.connector.connect(\n",
    "        host = 'localhost',\n",
    "        user = 'root',\n",
    "        passwd = 'root',\n",
    "        database = 'my_paper'\n",
    "        )\n",
    "    mycursor = mydb.cursor()\n",
    "    get_adult_age = 'SELECT * FROM adult'\n",
    "    mycursor.execute(get_adult_age)\n",
    "    result = mycursor.fetchall()\n",
    "    adult_age = tuple(a[0] for a in result)\n",
    "    return adult_age\n",
    "\n",
    "def br_age():\n",
    "    '''get dataset: br_age'''\n",
    "    mydb = mysql.connector.connect(\n",
    "        host = 'localhost',\n",
    "        user = 'root',\n",
    "        passwd = 'root',\n",
    "        database = 'my_paper'\n",
    "        )\n",
    "    mycursor = mydb.cursor()\n",
    "    get_br_age = 'SELECT * FROM br_age'\n",
    "    mycursor.execute(get_br_age)\n",
    "    result = mycursor.fetchall()\n",
    "    br_age = tuple(a[0] for a in result)\n",
    "    return br_age\n",
    "\n",
    "def us_age():\n",
    "    '''get dataset: us_age'''\n",
    "    mydb = mysql.connector.connect(\n",
    "        host = 'localhost',\n",
    "        user = 'root',\n",
    "        passwd = 'root',\n",
    "        database = 'my_paper'\n",
    "        )\n",
    "    mycursor = mydb.cursor()\n",
    "    get_us_age = 'SELECT * FROM us_age'\n",
    "    mycursor.execute(get_us_age)\n",
    "    result = mycursor.fetchall()\n",
    "    us_age = tuple(a[0] for a in result)\n",
    "    return us_age\n",
    "\n",
    "def brazil():\n",
    "    '''get dataset: BR'''\n",
    "    mydb = mysql.connector.connect(\n",
    "        host  = 'localhost',\n",
    "        user = 'root',\n",
    "        passwd = 'root',\n",
    "        database = 'my_paper'\n",
    "        )\n",
    "    mycursor = mydb.cursor()\n",
    "    get_br= 'SELECT * FROM brazil'\n",
    "    mycursor.execute(get_br)\n",
    "    result = mycursor.fetchall()\n",
    "    br_y = tuple(a[-1] for a in result)\n",
    "    br_x = tuple(a[:-1] for a in result)\n",
    "    return br_x, br_y\n",
    "\n",
    "def us():\n",
    "    '''get dataset: US'''\n",
    "    mydb = mysql.connector.connect(\n",
    "        host  = 'localhost',\n",
    "        user = 'root',\n",
    "        passwd = 'root',\n",
    "        database = 'my_paper'\n",
    "        )\n",
    "    mycursor = mydb.cursor()\n",
    "    get_us= 'SELECT * FROM usa'\n",
    "    mycursor.execute(get_us)\n",
    "    result = mycursor.fetchall()\n",
    "    us_y = tuple(a[-1] for a in result)\n",
    "    us_x = tuple(a[:-1] for a in result)\n",
    "    return us_x, us_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32fab86",
   "metadata": {},
   "source": [
    "### 2 实验一、不同的数据重复次数$\\mu$\n",
    "在Adult_AGE数据集上，改变$\\mu$值，观察利用HierA方法进行均值估计时的准确性。使用MAE作为评价指标，T=100。设置隐私预算为：$\\{5\\epsilon,4\\epsilon,3\\epsilon,2\\epsilon,\\epsilon\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd8e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_division = (-1, -0.6, -0.2, 0.2, 0.6, 1)\n",
    "epsilon_list = (0.25,0.5, 1, 1.5, 2, 2.5)\n",
    "mus = (1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c971ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def var_mu(userdata: tuple, range_division:tuple, \\\n",
    "                epsilon_list: tuple, mus:tuple) ->dict:\n",
    "    m_true = sum(userdata)/len(userdata)\n",
    "    mae_mus = {i: [] for i in mus}\n",
    "    for mu in mus:\n",
    "        mae_mu = []\n",
    "        for epsilon in epsilon_list:\n",
    "            ae = []\n",
    "            epsilons = tuple(i*epsilon for i in np.arange(5, 0, -1))\n",
    "            for i in range(100):\n",
    "                m = HierA(userdata, range_division, epsilons, mu)\n",
    "                ae.append(abs(m - m_true))\n",
    "            mae_mu.append(sum(ae) / len(ae))\n",
    "        mae_mus[mu] = mae_mu\n",
    "    return mae_mus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c587cba",
   "metadata": {},
   "source": [
    "### 3 实验二、不同方法的比较\n",
    "在不同数据集上，比较使用Harmony、PM、multi_laplace和HierA方法对用户数据进行隐私保护并进行均值估计的准确性，使用MAE作为评价指标，T=10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "540d9c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Harmony import Harmony\n",
    "from PiecewiseMechanism import PiecewiseMechanism as PM\n",
    "from multi_laplace import MultiLaplace  as Multi_Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "587f9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_methods(userdata:tuple, range_division: tuple, epsilon_list: tuple, mu=2):\n",
    "    '''横向对比'''\n",
    "    mae = {'harmony': [], 'pm': [], 'laplace': [], 'hiera': []}\n",
    "    methods = ('harmony', 'pm', 'laplace', 'hiera')\n",
    "    np_userdata = np.array(userdata)   \n",
    "    m_true = np_userdata.mean()\n",
    "    \n",
    "    for epsilon in epsilon_list:\n",
    "        ae_1, ae_2, ae_3, ae_4 = [], [], [], []\n",
    "        harmony = np.vectorize(Harmony(epsilon).encode)\n",
    "        pm = np.vectorize(PM(epsilon).encode)\n",
    "    \n",
    "        epsilons = tuple(i*epsilon for i in np.arange(5, 0, -1))\n",
    "        multi_laplace = np.vectorize(Multi_Laplace(range_division, epsilons).encode)\n",
    "        \n",
    "        for i in range(100):\n",
    "            m_harmony = harmony(np_userdata).mean()\n",
    "            m_pm = pm(np_userdata).mean()\n",
    "            m_laplace = multi_laplace(np_userdata).mean()\n",
    "            m_hiera = HierA(userdata, range_division, epsilons,mu)\n",
    "            for m_, ae_ in zip((m_harmony, m_pm, m_laplace, m_hiera), (ae_1, ae_2, ae_3, ae_4)):\n",
    "                ae_.append(abs(m_ - m_true))\n",
    "\n",
    "        for method, ae in zip(methods, (ae_1, ae_2, ae_3, ae_4)):\n",
    "            mae[method].append(sum(ae) / len(ae))\n",
    "\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bad3a0",
   "metadata": {},
   "source": [
    "### 4 实验三、小批量随机梯度下降\n",
    "在BR数据集和US数据集上，将“总收入”属性作为输出Y，其他属性作为输入X，使用小批量随机梯度下降方法，进行多元线性回归实验。使用5折交叉验证的均方误差MSE作为评价指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7c6e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Harmony import Harmony\n",
    "from PiecewiseMechanism import PiecewiseMechanism as PM\n",
    "from multi_laplace import MultiLaplace  as Multi_Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e8a19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_folds_sgd(x:tuple, y:tuple, sgd, range_division: tuple, epsilon: float):\n",
    "    '''横向对比'''\n",
    "    r_num = len(y)\n",
    "    se = []\n",
    "    for i in range(5):\n",
    "        for i in range(5):\n",
    "            test_x = x[i*r_num//5: (i+1)*r_num//5]\n",
    "            test_y = y[i*r_num//5: (i+1)*r_num//5]\n",
    "            train_x = x[0: i*r_num//5] + x[(i+1)*r_num//5:]\n",
    "            train_y = y[0: i*r_num//5] + y[(i+1)*r_num//5:]\n",
    "\n",
    "            beta = sgd(train_x, train_y, range_division, epsilon)\n",
    "\n",
    "            for j in range(len(test_y)):\n",
    "                se.append((predict_f(beta, [1]+list(x[j])) - test_y[j])**2)\n",
    "                \n",
    "    mse = sum(se)/len(se)\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5591b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_methods_sgd(x:tuple, y:tuple, range_division:tuple, epsilon_list:tuple, mu=2, lam=0.0001):\n",
    "    mse = {'Harmony':[], 'PM':[], '分级的laplace': [], 'HierA':[]}\n",
    "    \n",
    "    for epsilon in epsilon_list:\n",
    "        mse['Harmony'].append(five_folds_sgd(x, y, harmony_mb_sgd, range_division, epsilon))\n",
    "        mse['PM'].append(five_folds_sgd(x, y, pm_mb_sgd, range_division, epsilon))\n",
    "        mse['分级的laplace'].append(five_folds_sgd(x, y, multilaplace_mb_sgd, range_division, epsilon))\n",
    "        mse['HierA'].append(five_folds_sgd(x, y, hiera_mb_sgd, range_division, epsilon))\n",
    "    return mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
